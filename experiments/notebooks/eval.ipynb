{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/caleml/main-pe/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from data.datasets.h36m import Human36M\n",
    "from data.loader import BatchLoader\n",
    "from data.utils import transform, camera\n",
    "from data.utils.data_utils import TEST_MODE, TRAIN_MODE, VALID_MODE\n",
    "\n",
    "from model import config, measures\n",
    "from model.networks.multi_branch_model import MultiBranchModel\n",
    "from model.utils import pose_format, log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local loading\n",
    "local_h36m_path = '/home/caleml/datasets/h36m'\n",
    "local_h36m = Human36M(local_h36m_path, dataconf=config.human36m_dataconf, poselayout=pose_format.pa17j3d, topology='frames') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mPreloading Human3.6M validation samples...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "h36m_val = BatchLoader(local_h36m, \n",
    "                       ['frame'],\n",
    "                       ['pose_w', 'pose_uvd', 'afmat', 'camera'], \n",
    "                       VALID_MODE,\n",
    "                       batch_size=local_h36m.get_length(VALID_MODE), \n",
    "                       shuffle=True)\n",
    "\n",
    "log.printcn(log.OKBLUE, 'Preloading Human3.6M validation samples...')\n",
    "\n",
    "[x_val], [pw_val, puvd_val, afmat_val, scam_val] = h36m_val[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose shape (?, 17, 3), vis shape (?, 17, 1), concat shape (?, 17, 4)\n",
      "pose y_pred shape (?, 17, 4)\n",
      "Shape (?, ?, ?)\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Stem (Model)                    (None, 32, 32, 576)  1039488     input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "rBlock1 (Model)                 (None, 32, 32, 576)  1312128     Stem[1][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "SepConv1 (Model)                (None, 32, 32, 576)  347904      rBlock1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "RegMap1 (Model)                 (None, 32, 32, 272)  156672      SepConv1[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 32, 32, 16, 1 0           RegMap1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 32, 32, 17)   0           lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 16, 17)       0           lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_2 (GlobalM (None, 17)           0           lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 17)           0           lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 17)           0           global_max_pooling2d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "model_6 (Model)                 (None, 17, 2)        35394       lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zSAM_softmax (Model)            (None, 17, 1)        4624        lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 17, 1)        0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 17, 3)        0           model_6[1][0]                    \n",
      "                                                                 zSAM_softmax[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 1)        0           lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 17, 4)        0           concatenate_16[0][0]             \n",
      "                                                                 activation_46[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,896,210\n",
      "Trainable params: 2,844,096\n",
      "Non-trainable params: 52,114\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weights_path = '/home/caleml/pe_experiments/test_from_gpuserver2/weights_036.h5'\n",
    "eval_model = MultiBranchModel(dim=3, n_joints=17, nb_pose_blocks=1)\n",
    "eval_model.load_weights(weights_path, pose_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8695/8695==============================] - 49s 6ms/sample\n",
      "\u001b[93mAvg. mm. error:\u001b[0m\u001b[93m 74.2\u001b[0m\u001b[0m\n",
      "\u001b[93mFinal averaged error (mm): 74.217\u001b[0m\n",
      "[74.21665599332593]\n"
     ]
    }
   ],
   "source": [
    "scores = eval_human36m_sc_error(eval_model.model, \n",
    "                                x_val, \n",
    "                                pw_val, \n",
    "                                afmat_val,\n",
    "                                puvd_val[:,0,2], \n",
    "                                scam_val,  \n",
    "                                batch_size=24)\n",
    "\n",
    "pprint(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_human36m_sc_error(model,\n",
    "                           x,\n",
    "                           pose_w,\n",
    "                           afmat,\n",
    "                           rootz,\n",
    "                           scam,\n",
    "                           resol_z=2000.,\n",
    "                           batch_size=8,\n",
    "                           map_to_pa17j=None,\n",
    "                           logdir=None,\n",
    "                           verbose=True):\n",
    "\n",
    "    assert len(x) == len(pose_w) == len(afmat) == len(scam)\n",
    "\n",
    "    num_blocks = len(model.outputs)\n",
    "\n",
    "    y_true_w = pose_w.copy()\n",
    "    if map_to_pa17j is not None:\n",
    "        y_true_w = y_true_w[:, map_to_pa17j, :]\n",
    "    y_pred_w = np.zeros((num_blocks,) + y_true_w.shape)\n",
    "    if rootz.ndim == 1:\n",
    "        rootz = np.expand_dims(rootz, axis=-1)\n",
    "\n",
    "    pred = model.predict(x, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Move the root joints from GT poses to origin\n",
    "    y_true_w -= y_true_w[:, 0:1, :]\n",
    "\n",
    "    if verbose:\n",
    "        log.printc(log.WARNING, 'Avg. mm. error:')\n",
    "\n",
    "    lower_err = np.inf\n",
    "    scores = []\n",
    "\n",
    "    for b in range(num_blocks):\n",
    "\n",
    "        if num_blocks > 1:\n",
    "            y_pred = pred[b]\n",
    "        else:\n",
    "            y_pred = pred\n",
    "\n",
    "        # ??\n",
    "        y_pred = y_pred[:, :, 0:3]\n",
    "\n",
    "        # project normalized coordiates to the image plane\n",
    "        y_pred[:, :, 0:2] = transform.transform_pose_sequence(afmat.copy(), y_pred[:, :, 0:2], inverse=True)\n",
    "\n",
    "        # Recover the absolute Z\n",
    "        y_pred[:, :, 2] = (resol_z * (y_pred[:, :, 2] - 0.5)) + rootz\n",
    "        y_pred_uvd = y_pred[:, :, 0:3]\n",
    "\n",
    "        # camera inverse projection\n",
    "        for j in range(len(y_pred_uvd)):\n",
    "            cam = camera.camera_deserialize(scam[j])\n",
    "            y_pred_w[b, j, :, :] = cam.inverse_project(y_pred_uvd[j])\n",
    "\n",
    "        # Move the root joint from predicted poses to the origin\n",
    "        y_pred_w[b, :, :, :] -= y_pred_w[b, :, 0:1, :]\n",
    "\n",
    "        err_w = measures.mean_distance_error(y_true_w[:, 0:, :], y_pred_w[b, :, 0:, :])\n",
    "        scores.append(err_w)\n",
    "        if verbose:\n",
    "            log.printc(log.WARNING, ' %.1f' % err_w)\n",
    "\n",
    "        # Keep the best prediction\n",
    "        if err_w < lower_err:\n",
    "            lower_err = err_w\n",
    "\n",
    "    if verbose:\n",
    "        log.printcn('', '')\n",
    "\n",
    "    if logdir is not None:\n",
    "        np.save('%s/y_pred_w.npy' % logdir, y_pred_w)\n",
    "        np.save('%s/y_true_w.npy' % logdir, y_true_w)\n",
    "\n",
    "    log.printcn(log.WARNING, 'Final averaged error (mm): %.3f' % lower_err)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
