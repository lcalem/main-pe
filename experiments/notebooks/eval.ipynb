{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib.machinery\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/caleml/main-pe/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from data.datasets.h36m import Human36M\n",
    "from data.loader import BatchLoader\n",
    "from data.utils import transform, camera\n",
    "from data.utils.data_utils import TEST_MODE, TRAIN_MODE, VALID_MODE\n",
    "\n",
    "from model import config, measures\n",
    "from model.utils import pose_format, log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local loading\n",
    "local_h36m_path = '/home/caleml/datasets/h36m'\n",
    "local_h36m = Human36M(local_h36m_path, dataconf=config.human36m_dataconf, poselayout=pose_format.pa17j3d, topology='frames') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mPreloading Human3.6M validation samples...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "h36m_val = BatchLoader(local_h36m, \n",
    "                       ['frame'],\n",
    "                       ['pose_w', 'pose_uvd', 'afmat', 'camera'], \n",
    "                       VALID_MODE,\n",
    "                       batch_size=local_h36m.get_length(VALID_MODE), \n",
    "                       shuffle=True)\n",
    "\n",
    "log.printcn(log.OKBLUE, 'Preloading Human3.6M validation samples...')\n",
    "\n",
    "[x_val], [pw_val, puvd_val, afmat_val, scam_val] = h36m_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'x_val': x_val,\n",
    "    'pw_val': pw_val,\n",
    "    'puvd_val': puvd_val,\n",
    "    'afmat_val': afmat_val,\n",
    "    'scam_val': scam_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_human36m_sc_error(model,\n",
    "                           x,\n",
    "                           pose_w,\n",
    "                           afmat,\n",
    "                           rootz,\n",
    "                           scam,\n",
    "                           resol_z=2000.,\n",
    "                           batch_size=8,\n",
    "                           map_to_pa17j=None,\n",
    "                           logdir=None,\n",
    "                           verbose=True):\n",
    "\n",
    "    assert len(x) == len(pose_w) == len(afmat) == len(scam)\n",
    "\n",
    "    num_blocks = len(model.outputs)\n",
    "\n",
    "    y_true_w = pose_w.copy()\n",
    "    if map_to_pa17j is not None:\n",
    "        y_true_w = y_true_w[:, map_to_pa17j, :]\n",
    "    y_pred_w = np.zeros((num_blocks,) + y_true_w.shape)\n",
    "    if rootz.ndim == 1:\n",
    "        rootz = np.expand_dims(rootz, axis=-1)\n",
    "\n",
    "    pred = model.predict(x, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Move the root joints from GT poses to origin\n",
    "    y_true_w -= y_true_w[:, 0:1, :]\n",
    "\n",
    "    if verbose:\n",
    "        log.printc(log.WARNING, 'Avg. mm. error:')\n",
    "\n",
    "    lower_err = np.inf\n",
    "    scores = []\n",
    "\n",
    "    for b in range(num_blocks):\n",
    "\n",
    "        if num_blocks > 1:\n",
    "            y_pred = pred[b]\n",
    "        else:\n",
    "            y_pred = pred\n",
    "\n",
    "        # ??\n",
    "        y_pred = y_pred[:, :, 0:3]\n",
    "\n",
    "        # project normalized coordiates to the image plane\n",
    "        y_pred[:, :, 0:2] = transform.transform_pose_sequence(afmat.copy(), y_pred[:, :, 0:2], inverse=True)\n",
    "\n",
    "        # Recover the absolute Z\n",
    "        y_pred[:, :, 2] = (resol_z * (y_pred[:, :, 2] - 0.5)) + rootz\n",
    "        y_pred_uvd = y_pred[:, :, 0:3]\n",
    "\n",
    "        # camera inverse projection\n",
    "        for j in range(len(y_pred_uvd)):\n",
    "            cam = camera.camera_deserialize(scam[j])\n",
    "            y_pred_w[b, j, :, :] = cam.inverse_project(y_pred_uvd[j])\n",
    "\n",
    "        # Move the root joint from predicted poses to the origin\n",
    "        y_pred_w[b, :, :, :] -= y_pred_w[b, :, 0:1, :]\n",
    "\n",
    "        err_w = measures.mean_distance_error(y_true_w[:, 0:, :], y_pred_w[b, :, 0:, :])\n",
    "        scores.append(err_w)\n",
    "        if verbose:\n",
    "            log.printc(log.WARNING, ' %.1f' % err_w)\n",
    "\n",
    "        # Keep the best prediction\n",
    "        if err_w < lower_err:\n",
    "            lower_err = err_w\n",
    "\n",
    "    if verbose:\n",
    "        log.printcn('', '')\n",
    "\n",
    "    if logdir is not None:\n",
    "        np.save('%s/y_pred_w.npy' % logdir, y_pred_w)\n",
    "        np.save('%s/y_true_w.npy' % logdir, y_true_w)\n",
    "\n",
    "    log.printcn(log.WARNING, 'Final averaged error (mm): %.3f' % lower_err)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single h5 eval\n",
    "weights_path = '/home/caleml/pe_experiments/test_from_gpuserver2/weights_036.h5'\n",
    "eval_model = MultiBranchModel(dim=3, n_joints=17, nb_pose_blocks=1)\n",
    "eval_model.load_weights(weights_path, pose_only=True)\n",
    "scores = eval_human36m_sc_error(eval_model.model, \n",
    "                                x_val, \n",
    "                                pw_val, \n",
    "                                afmat_val,\n",
    "                                puvd_val[:,0,2], \n",
    "                                scam_val,  \n",
    "                                batch_size=24)\n",
    "\n",
    "pprint(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole folder eval\n",
    "def eval_folder(exp_folder, dataset, pose_only=False):\n",
    "    config_path = os.path.join(exp_folder, 'config.yaml')\n",
    "    \n",
    "    # config\n",
    "    with open(config_path, 'r') as f_conf:\n",
    "        config = yaml.load(f_conf)\n",
    "        \n",
    "    # model\n",
    "    # mb_module = importlib.machinery.SourceFileLoader('multi_branch_model', os.path.join(exp_folder, 'model_src/model/networks/multi_branch_model.py')).load_module()\n",
    "    # print(\"Model module loaded from %s\" % mb_module.__file__)\n",
    "    # eval_model = mb_module.MultiBranchModel(dim=3, n_joints=17, nb_pose_blocks=int(config['pose_blocks']))\n",
    "    from model.networks.multi_branch_model import MultiBranchModel\n",
    "    eval_model = MultiBranchModel(dim=3, n_joints=17, nb_pose_blocks=int(config['pose_blocks']))\n",
    "        \n",
    "    # find weights paths\n",
    "    weights = list()\n",
    "    for filename in os.listdir(exp_folder):\n",
    "        if filename.endswith(\".h5\") and filename.startswith(\"weights_\"):\n",
    "            weights.append(os.path.join(exp_folder, filename))\n",
    "            \n",
    "    weights.sort()\n",
    "    print(\"Found %s weights paths\" % len(weights))\n",
    "    \n",
    "    # actual eval\n",
    "    all_scores = list()\n",
    "    for i, weights_path in enumerate(weights):\n",
    "        time1 = time.time()\n",
    "        print(\"Eval of weights_path %s\" % weights_path)\n",
    "        eval_model.load_weights(weights_path, pose_only=pose_only)\n",
    "        \n",
    "        scores = eval_human36m_sc_error(eval_model.model, \n",
    "                                        dataset['x_val'], \n",
    "                                        dataset['pw_val'], \n",
    "                                        dataset['afmat_val'],\n",
    "                                        dataset['puvd_val'][:,0,2], \n",
    "                                        dataset['scam_val'],  \n",
    "                                        batch_size=24)\n",
    "        \n",
    "        time2 = time.time()\n",
    "        print(\"Scores for epoch %s: %s (in %s s)\" % (i + 1, str(scores), time2 - time1))\n",
    "        all_scores.append(max(scores))\n",
    "        \n",
    "    return all_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_baseline_path = '/home/caleml/pe_experiments/exp_baseline_1b_bs32_h36m_201903221052/'\n",
    "all_scores_baseline = eval_folder(exp_baseline_path, dataset, pose_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gud_layers\n",
      "gud_blocks\n",
      "Found 60 weights paths\n",
      "Eval of weights_path /home/caleml/pe_experiments/exp_20190322_1942_hybrid_h36m__1b_bs16/weights_001.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caleml/.local/lib/python3.4/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gud_pose\n",
      "pose shape (?, 17, 3), vis shape (?, 17, 1), concat shape (?, 17, 4)\n",
      "Last H shape Tensor(\"fReMap1/batch_normalization_13/cond/Merge:0\", shape=(?, 32, 32, 576), dtype=float32)\n",
      "gud_dec\n",
      "Build E_a 7.58323335647583, build E_p 5.7701873779296875, decoder D 0.6277205944061279\n",
      "Input shape (?, 256, 256, 3)\n",
      "Shape z_a (?, 16, 16, 1024), shape z_p (?, 16, 16, 1024)\n",
      "Outputs shape [(None, 256, 256, 3), (None, 17, 4)]\n",
      "rec y_pred shape (?, 256, 256, 3)\n",
      "pose y_pred shape (?, 17, 4)\n",
      "Shape (?, ?, ?)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 16, 16, 1024) 8589184     input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 [(None, 17, 4), (Non 3647506     input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16, 16, 2048) 0           model[1][0]                      \n",
      "                                                                 model_3[1][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 256, 256, 3)  26477979    concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 38,714,669\n",
      "Trainable params: 38,623,503\n",
      "Non-trainable params: 91,166\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bd1b5203dcd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexp_hybrid_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/caleml/pe_experiments/exp_20190322_1942_hybrid_h36m__1b_bs16/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# clean_pythonpath(exp_folder=exp_hybrid_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_scores_hybrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_hybrid_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-9d1d98cfcc64>\u001b[0m in \u001b[0;36meval_folder\u001b[0;34m(exp_folder, dataset, pose_only)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtime1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Eval of weights_path %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpose_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         scores = eval_human36m_sc_error(eval_model.model, \n",
      "\u001b[0;32m~/main-pe/model/networks/multi_branch_model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, weights_path, pose_only)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1542\u001b[0m         \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m         \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     weight_values = preprocess_weights_for_loading(\n\u001b[0;32m--> 796\u001b[0;31m         layer, weight_values, original_keras_version, original_backend)\n\u001b[0m\u001b[1;32m    797\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m       raise ValueError('Layer #' + str(k) + ' (named \"' + layer.name +\n",
      "\u001b[0;32m/usr/lib/python3.4/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[0;34m(layer, weights, original_keras_version, original_backend)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_nested_time_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sequential'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_nested_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mconvert_nested_model\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0moriginal_keras_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_keras_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             original_backend=original_backend))\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[0;34m(layer, weights, original_keras_version, original_backend)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_nested_time_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sequential'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_nested_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mconvert_nested_model\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0moriginal_keras_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_keras_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             original_backend=original_backend))\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[0;34m(layer, weights, original_keras_version, original_backend)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m       \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ConvLSTM2D'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, axes)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transpose'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "exp_hybrid_path = '/home/caleml/pe_experiments/exp_20190322_1942_hybrid_h36m__1b_bs16/'\n",
    "# clean_pythonpath(exp_folder=exp_hybrid_path)\n",
    "all_scores_hybrid = eval_folder(exp_hybrid_path, dataset, pose_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pythonpath(exp_folder=None):\n",
    "    print('before path %s' % str(sys.path))\n",
    "    clean_path = [p for p in sys.path if 'pe_experiments' not in p]\n",
    "    \n",
    "    if '/home/caleml/main-pe/' in clean_path:\n",
    "        clean_path.remove('/home/caleml/main-pe/')\n",
    "        \n",
    "    if '' in clean_path:\n",
    "        clean_path.remove('')\n",
    "    \n",
    "    if exp_folder:\n",
    "        clean_path.insert(0, os.path.join(exp_folder, 'model_src/'))\n",
    "    sys.path = clean_path\n",
    "    print('after path %s' % str(sys.path))\n",
    "    \n",
    "    \n",
    "def restore_pythonpath():\n",
    "    clean_pythonpath()\n",
    "    \n",
    "    if '' not in sys.path:\n",
    "        sys.path.insert(0, '')\n",
    "    \n",
    "    if '/home/caleml/main-pe/' not in sys.path:\n",
    "        sys.path.append('/home/caleml/main-pe/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_pythonpath()\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = list(range(60))\n",
    "\n",
    "plt.plot(x, all_scores_baseline, 'r')\n",
    "# plt.plot(x, all_scores_hybrid, 'b')\n",
    "plt.title('Baseline val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MPJPE')\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('/home/caleml/pe_experiments/exp_baseline_1b_bs32_h36m_201903221052/eval.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores_baseline = [91.75194501441577, 82.46205898898975, 79.4226132617545, 88.8355976647399, 84.02042960060331, 86.88580619918093, 86.67989807960359, 79.48412115594127, 78.59867146077222, 84.09675808749151, 76.1932848291697, 77.14141621003114, 78.2065916383256, 81.43181095386677, 78.58923745192591, 77.008543664543, 77.46245838987596, 76.31208539465088, 78.66618899639796, 75.53613154051648, 83.53373459959678, 76.01499659875537, 74.4797050967049, 79.84342586353483, 77.25320791938644, 76.69853350783292, 76.45083687520106, 77.09345226614492, 75.78290824659078, 77.9041891354044, 78.09753993393933, 76.60042799938726, 77.5805151579404, 78.8091096371011, 74.80468494705836, 74.2166559806093, 77.63991530864764, 77.89325147099139, 78.38807773666701, 80.47055450518361, 73.81642579401903 , 75.0416006683364 , 74.48196930787806 , 75.15854590724823 , 73.66802279838019 , 75.19603076463348 , 74.01143213366338 , 75.08591589680957 , 75.55668131643323 , 77.11394826271881 , 74.44167918712098 , 75.63973677387979 , 76.3378921014415 , 74.73289168541717 , 73.95828566807859 , 75.55537095370421 , 75.78301989366678 , 74.91063809506264 , 74.59803512567959 , 74.75948044066446]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
