{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/caleml/main-pe/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, Convolution2D, Activation, BatchNormalization, Reshape\n",
    "from tensorflow.keras.layers import Permute, add, concatenate\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.datasets.mpii import MpiiSinglePerson\n",
    "from data.datasets.h36m import Human36M\n",
    "from data.utils.data_utils import TEST_MODE, TRAIN_MODE, VALID_MODE\n",
    "from data.loader import BatchLoader\n",
    "\n",
    "from model import blocks\n",
    "from model import layers\n",
    "from model import losses\n",
    "from model import config\n",
    "from model import callbacks\n",
    "from model.utils import pose_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.networks.appearance_model import AppearanceModel\n",
    "from model.networks.pose_model import PoseModel\n",
    "from model.networks.multi_branch_model import MultiBranchModel\n",
    "\n",
    "# all models are now in their respective file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import SeparableConv2D\n",
    "from model.utils import math\n",
    "\n",
    "def lin_interpolation_2d(inp, dim):\n",
    "    num_rows, num_cols, num_filters = inp.get_shape().as_list()[1:]\n",
    "    conv = SeparableConv2D(num_filters, (num_rows, num_cols), use_bias=False)\n",
    "    x = conv(inp)\n",
    "\n",
    "    w = conv.get_weights()\n",
    "    w[0].fill(0)\n",
    "    w[1].fill(0)\n",
    "    linspace = math.linspace_2d(num_rows, num_cols, dim=dim)\n",
    "\n",
    "    for i in range(num_filters):\n",
    "        w[0][:,:, i, 0] = linspace[:,:]\n",
    "        w[1][0, 0, i, i] = 1.\n",
    "\n",
    "    conv.set_weights(w)\n",
    "    conv.trainable = False\n",
    "    \n",
    "    x = Lambda(lambda x: tf.squeeze(x, axis=1))(x)\n",
    "    x = Lambda(lambda x: tf.squeeze(x, axis=1))(x)\n",
    "    x = Lambda(lambda x: tf.expand_dims(x, axis=-1))(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h36m_path = \"/share/DEEPLEARNING/datasets/h36m\"\n",
    "mpii_path = \"/share/DEEPLEARNING/datasets/mpii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h36m dataset loading\n",
    "h36m = Human36M(h36m_path, dataconf=config.human36m_dataconf, poselayout=pose_format.pa17j3d, topology='frames')\n",
    "\n",
    "data_tr_h36m = BatchLoader(\n",
    "    h36m, \n",
    "    ['frame'], \n",
    "    ['frame', 'pose', 'pose', 'pose', 'pose'],\n",
    "    TRAIN_MODE, \n",
    "    batch_size=8,\n",
    "    shuffle=True)\n",
    "\n",
    "# batch_size=[batch_size_mpii, batch_size_mpii, batch_size_ar, batch_size_ar], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_tr_h36m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_tr_h36m.get_data(1, TRAIN_MODE)\n",
    "print(type(a), a.keys())\n",
    "print(a['pose'])\n",
    "print(\"pose shape %s\" % (str(a['pose'].shape)))\n",
    "print(\"frame shape %s\" % (str(a['frame'].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "h36m_val = BatchLoader(\n",
    "    h36m, \n",
    "    ['frame'],\n",
    "    ['pose_w', 'pose_uvd', 'afmat', 'camera', 'action'], \n",
    "    VALID_MODE,\n",
    "    batch_size=h36m.get_length(VALID_MODE), \n",
    "    shuffle=True)\n",
    "\n",
    "[x_val], [pw_val, puvd_val, afmat_val, scam_val, action] = h36m_val[0]\n",
    "\n",
    "h36m_callback = H36MEvalCallback(x_val, pw_val, afmat_val, puvd_val[:,0,2], scam_val, action, logdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpii = MpiiSinglePerson(mpii_path, dataconf=config.mpii_dataconf, poselayout=pose_format.pa17j3d)\n",
    "mpii = MpiiSinglePerson(mpii_path, dataconf=config.mpii_dataconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr_mpii = BatchLoader(\n",
    "    mpii, \n",
    "    ['frame'], \n",
    "    ['frame', 'pose', 'pose', 'pose', 'pose'], \n",
    "    TRAIN_MODE,\n",
    "    batch_size=20,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_tr_mpii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_tr_mpii.get_data(1, TRAIN_MODE)\n",
    "print(type(a), a.keys())\n",
    "print(a['pose'])\n",
    "print(\"pose shape %s\" % (str(a['pose'].shape)))\n",
    "print(\"frame shape %s\" % (str(a['frame'].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = data_tr_mpii[1]\n",
    "print(type(b), len(b))\n",
    "print(type(b[0]), len(b[0]))\n",
    "print(b[0][0].shape)\n",
    "print(type(b[1]), len(b[1]))\n",
    "print(b[1][0].shape, b[1][1].shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "img = b[0][0][0]\n",
    "print(img.shape)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder()\n",
    "model.build()\n",
    "\n",
    "# steps_per_epoch = h36m.get_length(TRAIN_MODE) // batch_size_h36m\n",
    "steps_per_epoch = mpii.get_length(TRAIN_MODE) // batch_size_mpii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data_tr, steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AppearanceModel()\n",
    "model.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'appearance'\n",
    "dataset_name = 'mpii'\n",
    "model_folder = '/home/caleml/pe_experiments/exp_%s_%s_%s' % (model_name, dataset_name, datetime.datetime.now().strftime(\"%Y%m%d%H%M\")) \n",
    "os.makedirs(model_folder)\n",
    "model.train(data_tr_mpii, steps_per_epoch=len(data_tr_mpii), model_folder=model_folder, n_epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multib mpii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiBranchModel(dim=2, n_joints=16, nb_pose_blocks=4)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multib'\n",
    "dataset_name = 'mpii'\n",
    "model_folder = '/home/caleml/pe_experiments/exp_%s_%s_%s' % (model_name, dataset_name, datetime.datetime.now().strftime(\"%Y%m%d%H%M\")) \n",
    "os.makedirs(model_folder)\n",
    "model.train(data_tr_mpii, steps_per_epoch=len(data_tr_mpii), model_folder=model_folder, n_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multib h36m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiBranchModel(dim=3, n_joints=17, nb_pose_blocks=4)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'separate'\n",
    "dataset_name = 'h36m'\n",
    "model_folder = '/home/caleml/pe_experiments/exp_%s_%s_%s' % (model_name, dataset_name, datetime.datetime.now().strftime(\"%Y%m%d%H%M\")) \n",
    "os.makedirs(model_folder)\n",
    "model.train(data_tr_h36m, steps_per_epoch=len(data_tr_h36m), model_folder=model_folder, n_epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline H36m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr_h36m = BatchLoader(\n",
    "        h36m, \n",
    "        ['frame'], \n",
    "        ['pose', 'pose', 'pose', 'pose'],\n",
    "        TRAIN_MODE, \n",
    "        batch_size=32,\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiBranchModel(dim=3, n_joints=17, nb_pose_blocks=8)\n",
    "model.build_pose_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'baseline'\n",
    "dataset_name = 'h36m'\n",
    "model_folder = '/home/caleml/pe_experiments/exp_%s_%s_%s' % (model_name, dataset_name, datetime.datetime.now().strftime(\"%Y%m%d%H%M\")) \n",
    "os.makedirs(model_folder)\n",
    "model.train(data_tr_h36m, steps_per_epoch=len(data_tr_h36m), model_folder=model_folder, n_epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appearance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = '/home/caleml/pe_experiments/exp_appearance_mpii_201902051901'\n",
    "model_checkpoint = '/home/caleml/pe_experiments/exp_appearance_mpii_201902051901/weights_mpii_058.h5'  # weights\n",
    "checkpoint_2 = '/home/caleml/pe_experiments/exp_appearance_mpii_201902061614/weights_mpii_013.h5'  # made with save_model\n",
    "\n",
    "model = AppearanceModel()\n",
    "model.load(checkpoint_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate model\n",
    "\n",
    "from model.activations import channel_softmax_2d\n",
    "from model.losses import reconstruction_loss, pose_loss\n",
    "\n",
    "checkpoint = \"/home/caleml/pe_experiments/exp_separate_mpii_201903081936/appearance_mpii_060.h5\"\n",
    "\n",
    "custom_objects = {\n",
    "    '_channel_softmax_2d': channel_softmax_2d(),\n",
    "    '_rec_loss': reconstruction_loss(),\n",
    "    '_pose_loss': pose_loss()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = MultiBranchModel()\n",
    "eval_model.load(checkpoint, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpii_eval = MpiiSinglePerson(mpii_path, dataconf=config.mpii_dataconf)\n",
    "data_val_mpii = BatchLoader(\n",
    "    mpii_eval, \n",
    "    ['frame'], \n",
    "    ['frame', 'pose', 'afmat', 'headsize'], \n",
    "    mode=VALID_MODE,\n",
    "    shuffle=False)\n",
    "\n",
    "len(data_val_mpii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mpii_pckh(model_class, x_val, pose_val, headsize_val, refp=0.5):\n",
    "    '''\n",
    "    assumes one prediction per block\n",
    "    '''\n",
    "    model = model_class.model\n",
    "    input_shape = model.inputs[0].shape\n",
    "    num_blocks = len(model.outputs) - 1  # -1 because of imag reconstruction output\n",
    "    \n",
    "    print(\"eval input shape %s, num blocks %s\" % (str(input_shape), num_blocks))\n",
    "    \n",
    "    print(\"eval data x: %s y: %s %s\" % (x_val.shape, pose_val.shape, headsize_val.shape))\n",
    "        \n",
    "    pred = model.predict(x_val)\n",
    "    print(pred[1].shape)\n",
    "    \n",
    "    scores = list()\n",
    "    print(pose_val[0])\n",
    "    print(pred[1][0])\n",
    "        \n",
    "    for i_block in range(num_blocks):\n",
    "        y_pred = pred[i_block + 1]\n",
    "        s = pckh(pose_val, y_pred, headsize_val, refp=refp)\n",
    "        scores.append(s)\n",
    "        \n",
    "        pckh_per_joint(pose_val, y_pred, headsize_val, pose_format.pa16j2d, verbose=1)\n",
    "        \n",
    "    print(scores)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pckh(y_true, y_pred, head_size, refp=0.5):\n",
    "    '''\n",
    "    Compute the PCKh measure (using refp of the head size) on predicted samples\n",
    "    \n",
    "    y_true: [batch_size, nb_joints, 2]\n",
    "    y_pred: [batch_size, nb_joints, 2]\n",
    "    head_size: [batch_size, 1]\n",
    "    '''\n",
    "\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    assert len(y_true) == len(head_size)\n",
    "    num_samples = len(y_true)\n",
    "\n",
    "    # Ignore the joints 6 and 7 (pelvis and thorax respectively), according to the file 'annolist2matrix.m' WHY\n",
    "    used_joints = [2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 8, 9]\n",
    "    y_true = y_true[:, used_joints, :]\n",
    "    y_pred = y_pred[:, used_joints, :]\n",
    "    dist = np.zeros((num_samples, len(used_joints)))\n",
    "    valid = np.zeros((num_samples, len(used_joints)))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        valid[i,:] = _valid_joints(y_true[i])\n",
    "        \n",
    "        norm = _norm(y_true[i] - y_pred[i], axis=1)\n",
    "        dist[i,:] = _norm(y_true[i] - y_pred[i], axis=1) / head_size[i]\n",
    "        print(\"distance norm between true %s and pred %s : %s (head size %s)\" % (str(y_true[i]), str(y_pred[i]), norm, head_size[i]))\n",
    "    match = (dist <= refp) * valid\n",
    "\n",
    "    return match.sum() / valid.sum()\n",
    "\n",
    "\n",
    "def pckh_per_joint(y_true, y_pred, head_size, pose_layout, refp=0.5, verbose=1):\n",
    "    '''\n",
    "    Compute the PCKh measure (using refp of the head size) on predicted\n",
    "    samples per joint and output the results.\n",
    "\n",
    "    y_true: [num_samples, nb_joints, 2]\n",
    "    y_pred: [num_samples, nb_joints, 2]\n",
    "    head_size: [num_samples, 1]\n",
    "    pose_layout: from deephar.utils.pose\n",
    "    '''\n",
    "\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    assert len(y_true) == len(head_size)\n",
    "\n",
    "    num_samples = len(y_true)\n",
    "    num_joints = pose_layout.num_joints\n",
    "    dist = np.zeros((num_samples, num_joints))\n",
    "    valid = np.zeros((num_samples, num_joints))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        valid[i,:] = _valid_joints(y_true[i])\n",
    "        dist[i,:] = _norm(y_true[i] - y_pred[i], axis=1) / head_size[i]\n",
    "\n",
    "    for j in range(num_joints):\n",
    "        jname = pose_layout.joint_names[j]\n",
    "        space = 7*' '\n",
    "        ss = len(space) - len(jname)\n",
    "        if verbose:\n",
    "            printc(HEADER, jname + space[0:ss] + '| ')\n",
    "    if verbose:\n",
    "        print ('')\n",
    "\n",
    "    match = (dist <= refp) * valid\n",
    "    for j in range(num_joints):\n",
    "        pck = match[:, j].sum() / valid[:, j].sum()\n",
    "        if verbose:\n",
    "            printc(OKBLUE, ' %.2f | ' % (100 * pck))\n",
    "    if verbose:\n",
    "        print ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "HEADER = '\\033[95m'\n",
    "OKBLUE = '\\033[94m'\n",
    "OKGREEN = '\\033[92m'\n",
    "WARNING = '\\033[93m'\n",
    "FAIL = '\\033[91m'\n",
    "ENDC = '\\033[0m'\n",
    "\n",
    "def printc(color, vmsg):\n",
    "    print (color + vmsg + ENDC, end='')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def _valid_joints(y, min_valid=-1e6):\n",
    "    def and_all(x):\n",
    "        if x.all():\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    return np.apply_along_axis(and_all, axis=1, arr=(y > min_valid))\n",
    "\n",
    "def _norm(x, axis=None):\n",
    "    return np.sqrt(np.sum(np.power(x, 2), axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x_val], [y_val, pose_val, afmat_val, head_val] = data_val_mpii[0]\n",
    "eval_mpii_pckh(eval_model, x_val, pose_val, head_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_val_mpii.get_data(1, VALID_MODE)\n",
    "print(data['frame'].shape)\n",
    "pred = eval_model.predict(data['frame'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_cols = 2\n",
    "n_rows = len(data['frame'])\n",
    "fig = plt.figure(figsize=(8, 75))\n",
    "\n",
    "print(len(data['frame']))\n",
    "print(len(pred[0]))\n",
    "\n",
    "i_img = 1\n",
    "for i, data_img in enumerate(data['frame']):\n",
    "    fig.add_subplot(n_rows, n_cols, i_img)\n",
    "    plt.imshow(data_img)\n",
    "    \n",
    "    pred_img = pred[0][i]\n",
    "    fig.add_subplot(n_rows, n_cols, i_img + 1)\n",
    "    plt.imshow(pred_img)\n",
    "    \n",
    "    i_img += 2\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pred[0][0]\n",
    "print(img.shape)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "data_img = data['frame'][0]\n",
    "imgplot = plt.imshow(data_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pouet(definition):\n",
    "    \n",
    "    ret = list()\n",
    "    for elt in definition:\n",
    "        ret.append('truc')\n",
    "        \n",
    "    return tuple(ret)\n",
    "\n",
    "a = pouet('a')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(i):\n",
    "    def loss(a):\n",
    "        return a * i\n",
    "    return loss\n",
    "\n",
    "losses = list()\n",
    "for i in range(10):\n",
    "    losses.append(wrapper(i))\n",
    "    \n",
    "print(len(losses))\n",
    "for loss_fn in losses:\n",
    "    print(loss_fn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
