{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/caleml/main-pe/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, Convolution2D, Activation, BatchNormalization, Reshape\n",
    "from tensorflow.keras.layers import Permute, add, concatenate\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.datasets.mpii import MpiiSinglePerson\n",
    "from data.datasets.h36m import Human36M\n",
    "from data.utils.data_utils import TEST_MODE, TRAIN_MODE, VALID_MODE\n",
    "from data.loader import BatchLoader\n",
    "\n",
    "from experiments.common import exp_init\n",
    "\n",
    "from model import blocks\n",
    "from model import layers\n",
    "from model import losses\n",
    "from model import config\n",
    "from model import callbacks\n",
    "from model.utils import pose_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.networks.appearance_model import AppearanceModel\n",
    "from model.networks.pose_model import PoseModel\n",
    "from model.networks.multi_branch_model import MultiBranchModel\n",
    "\n",
    "# all models are now in their respective file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut the Resnet50\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "inp = Input(shape=input_shape)\n",
    "enc_model = ResNet50(include_top=False, weights='imagenet', input_tensor=inp)\n",
    "z_a = enc_model.output   # 8 x 8 x 2048\n",
    "print(z_a.shape)\n",
    "\n",
    "output_layer = enc_model.layers[-33]\n",
    "print(output_layer.name)\n",
    "smaller_model = Model(inputs=enc_model.inputs, outputs=output_layer.output)\n",
    "z_a2= smaller_model.output\n",
    "print(z_a2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import SeparableConv2D\n",
    "from model.utils import math\n",
    "\n",
    "def lin_interpolation_2d(inp, dim):\n",
    "    num_rows, num_cols, num_filters = inp.get_shape().as_list()[1:]\n",
    "    conv = SeparableConv2D(num_filters, (num_rows, num_cols), use_bias=False)\n",
    "    x = conv(inp)\n",
    "\n",
    "    w = conv.get_weights()\n",
    "    w[0].fill(0)\n",
    "    w[1].fill(0)\n",
    "    linspace = math.linspace_2d(num_rows, num_cols, dim=dim)\n",
    "\n",
    "    for i in range(num_filters):\n",
    "        w[0][:,:, i, 0] = linspace[:,:]\n",
    "        w[1][0, 0, i, i] = 1.\n",
    "\n",
    "    conv.set_weights(w)\n",
    "    conv.trainable = False\n",
    "    \n",
    "    x = Lambda(lambda x: tf.squeeze(x, axis=1))(x)\n",
    "    x = Lambda(lambda x: tf.squeeze(x, axis=1))(x)\n",
    "    x = Lambda(lambda x: tf.expand_dims(x, axis=-1))(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h36m_path = \"/share/DEEPLEARNING/datasets/h36m\"\n",
    "mpii_path = \"/share/DEEPLEARNING/datasets/mpii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h36m dataset loading\n",
    "h36m = Human36M(h36m_path, dataconf=config.human36m_dataconf, poselayout=pose_format.pa17j3d, topology='frames') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr_h36m = BatchLoader(\n",
    "    h36m, \n",
    "    ['frame'], \n",
    "    ['frame', 'pose', 'pose', 'pose', 'pose'],\n",
    "    TRAIN_MODE, \n",
    "    batch_size=8,\n",
    "    shuffle=True)\n",
    "\n",
    "# batch_size=[batch_size_mpii, batch_size_mpii, batch_size_ar, batch_size_ar],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local loading\n",
    "local_h36m_path = '/home/caleml/datasets/h36m'\n",
    "local_h36m = Human36M(local_h36m_path, dataconf=config.human36m_dataconf, poselayout=pose_format.pa17j3d, topology='frames') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_tr_h36m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_tr_h36m.get_data(1, TRAIN_MODE)\n",
    "print(type(a), a.keys())\n",
    "print(a['pose'])\n",
    "print(\"pose shape %s\" % (str(a['pose'].shape)))\n",
    "print(\"frame shape %s\" % (str(a['frame'].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "h36m_val = BatchLoader(\n",
    "    h36m, \n",
    "    ['frame'],\n",
    "    ['pose_w', 'pose_uvd', 'afmat', 'camera', 'action'], \n",
    "    VALID_MODE,\n",
    "    batch_size=h36m.get_length(VALID_MODE), \n",
    "    shuffle=True)\n",
    "\n",
    "[x_val], [pw_val, puvd_val, afmat_val, scam_val, action] = h36m_val[0]\n",
    "\n",
    "h36m_callback = H36MEvalCallback(x_val, pw_val, afmat_val, puvd_val[:,0,2], scam_val, action, logdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpii = MpiiSinglePerson(mpii_path, dataconf=config.mpii_dataconf, poselayout=pose_format.pa17j3d)\n",
    "mpii = MpiiSinglePerson(mpii_path, dataconf=config.mpii_dataconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr_mpii = BatchLoader(\n",
    "    mpii, \n",
    "    ['frame'], \n",
    "    ['frame', 'pose', 'pose', 'pose', 'pose'], \n",
    "    TRAIN_MODE,\n",
    "    batch_size=20,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_tr_mpii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_tr_mpii.get_data(1, TRAIN_MODE)\n",
    "print(type(a), a.keys())\n",
    "print(a['pose'])\n",
    "print(\"pose shape %s\" % (str(a['pose'].shape)))\n",
    "print(\"frame shape %s\" % (str(a['frame'].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = data_tr_mpii[1]\n",
    "print(type(b), len(b))\n",
    "print(type(b[0]), len(b[0]))\n",
    "print(b[0][0].shape)\n",
    "print(type(b[1]), len(b[1]))\n",
    "print(b[1][0].shape, b[1][1].shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "img = b[0][0][0]\n",
    "print(img.shape)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder()\n",
    "model.build()\n",
    "\n",
    "# steps_per_epoch = h36m.get_length(TRAIN_MODE) // batch_size_h36m\n",
    "steps_per_epoch = mpii.get_length(TRAIN_MODE) // batch_size_mpii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data_tr, steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AppearanceModel()\n",
    "model.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'appearance'\n",
    "dataset_name = 'mpii'\n",
    "model_folder = '/home/caleml/pe_experiments/exp_%s_%s_%s' % (model_name, dataset_name, datetime.datetime.now().strftime(\"%Y%m%d%H%M\")) \n",
    "os.makedirs(model_folder)\n",
    "model.train(data_tr_mpii, steps_per_epoch=len(data_tr_mpii), model_folder=model_folder, n_epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multib mpii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiBranchModel(dim=2, n_joints=16, nb_pose_blocks=4)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multib'\n",
    "dataset_name = 'mpii'\n",
    "model_folder = '/home/caleml/pe_experiments/exp_%s_%s_%s' % (model_name, dataset_name, datetime.datetime.now().strftime(\"%Y%m%d%H%M\")) \n",
    "os.makedirs(model_folder)\n",
    "model.train(data_tr_mpii, steps_per_epoch=len(data_tr_mpii), model_folder=model_folder, n_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid h36m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    'dim': 3,\n",
    "    'n_joints': 17,\n",
    "    'pose_blocks': 4,\n",
    "    'model_name': 'hybrid_4b',\n",
    "    'dataset_name': 'h36m',\n",
    "    'batch_size': 8,\n",
    "    'n_epochs': 60\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr_h36m = BatchLoader(\n",
    "        h36m, \n",
    "        ['frame'], \n",
    "        ['frame'] + ['pose'] * conf['pose_blocks'],\n",
    "        TRAIN_MODE, \n",
    "        batch_size=conf['batch_size'],\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiBranchModel(dim=conf['dim'], n_joints=conf['n_joints'], nb_pose_blocks=conf['pose_blocks'])\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = exp_init(conf)\n",
    "model.train(data_tr_h36m, steps_per_epoch=len(data_tr_h36m), model_folder=model_folder, n_epochs=conf['n_epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline H36m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_base = {\n",
    "    'dim': 3,\n",
    "    'n_joints': 17,\n",
    "    'pose_blocks': 1,\n",
    "    'model_name': 'cycle_1b_NB',\n",
    "    'dataset_name': 'h36m',\n",
    "    'batch_size': 16,\n",
    "    'n_epochs': 60\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr_h36m = BatchLoader(\n",
    "        local_h36m, \n",
    "        ['frame'], \n",
    "        ['pose'] * conf_base['pose_blocks'],\n",
    "        TRAIN_MODE, \n",
    "        batch_size=conf_base['batch_size'],\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiBranchModel(dim=conf_base['dim'], n_joints=conf_base['n_joints'], nb_pose_blocks=conf_base['pose_blocks'])\n",
    "model.build_pose_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'baseline_testepochend'\n",
    "dataset_name = 'h36m'\n",
    "model_folder = '/home/caleml/pe_experiments/exp_%s_%s_%s' % (model_name, dataset_name, datetime.datetime.now().strftime(\"%Y%m%d%H%M\")) \n",
    "os.makedirs(model_folder)\n",
    "model.train(data_tr_h36m, steps_per_epoch=10, model_folder=model_folder, n_epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle H36m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_cycle = {\n",
    "    'dim': 3,\n",
    "    'n_joints': 17,\n",
    "    'pose_blocks': 2,\n",
    "    'model_name': 'cycle_2b_local_TEST',\n",
    "    'dataset_name': 'h36m',\n",
    "    'batch_size': 8,\n",
    "    'n_epochs': 60\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr_h36m = BatchLoader(\n",
    "        local_h36m, \n",
    "        ['frame'], \n",
    "        ['frame'] + ['pose'] * conf_cycle['pose_blocks'] + ['action'] * 3,\n",
    "        TRAIN_MODE, \n",
    "        batch_size=conf_cycle['batch_size'],\n",
    "        shuffle=True)\n",
    "\n",
    "# the 3 last 'action' are phony y_true for internal loss hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.networks.cycle_model import CycleModel\n",
    "model = CycleModel(dim=conf_cycle['dim'], n_joints=conf_cycle['n_joints'], nb_pose_blocks=conf_cycle['pose_blocks'])\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = exp_init(conf_cycle)\n",
    "model.train(data_tr_h36m, steps_per_epoch=len(data_tr_h36m), model_folder=model_folder, n_epochs=conf_cycle['n_epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appearance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = '/home/caleml/pe_experiments/exp_appearance_mpii_201902051901'\n",
    "model_checkpoint = '/home/caleml/pe_experiments/exp_appearance_mpii_201902051901/weights_mpii_058.h5'  # weights\n",
    "checkpoint_2 = '/home/caleml/pe_experiments/exp_appearance_mpii_201902061614/weights_mpii_013.h5'  # made with save_model\n",
    "\n",
    "model = AppearanceModel()\n",
    "model.load(checkpoint_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate model\n",
    "\n",
    "from model.activations import channel_softmax_2d\n",
    "from model.losses import reconstruction_loss, pose_loss\n",
    "\n",
    "checkpoint = \"/home/caleml/pe_experiments/exp_separate_mpii_201903081936/appearance_mpii_060.h5\"\n",
    "\n",
    "custom_objects = {\n",
    "    '_channel_softmax_2d': channel_softmax_2d(),\n",
    "    '_rec_loss': reconstruction_loss(),\n",
    "    '_pose_loss': pose_loss()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = MultiBranchModel(dim=2)\n",
    "eval_model.load(checkpoint, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpii_eval = MpiiSinglePerson(mpii_path, dataconf=config.mpii_dataconf)\n",
    "data_val_mpii = BatchLoader(\n",
    "    mpii_eval, \n",
    "    ['frame'], \n",
    "    ['frame', 'pose', 'afmat', 'headsize'], \n",
    "    mode=VALID_MODE,\n",
    "    shuffle=False)\n",
    "\n",
    "len(data_val_mpii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mpii_pckh(model_class, x_val, pose_val, headsize_val, refp=0.5):\n",
    "    '''\n",
    "    assumes one prediction per block\n",
    "    '''\n",
    "    model = model_class.model\n",
    "    input_shape = model.inputs[0].shape\n",
    "    num_blocks = len(model.outputs) - 1  # -1 because of imag reconstruction output\n",
    "    \n",
    "    print(\"eval input shape %s, num blocks %s\" % (str(input_shape), num_blocks))\n",
    "    \n",
    "    print(\"eval data x: %s y: %s %s\" % (x_val.shape, pose_val.shape, headsize_val.shape))\n",
    "        \n",
    "    pred = model.predict(x_val)\n",
    "    print(pred[1].shape)\n",
    "    \n",
    "    scores = list()\n",
    "    print(pose_val[0])\n",
    "    print(pred[1][0])\n",
    "        \n",
    "    for i_block in range(num_blocks):\n",
    "        y_pred = pred[i_block + 1]\n",
    "        s = pckh(pose_val, y_pred, headsize_val, refp=refp)\n",
    "        scores.append(s)\n",
    "        \n",
    "        pckh_per_joint(pose_val, y_pred, headsize_val, pose_format.pa16j2d, verbose=1)\n",
    "        \n",
    "    print(scores)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pckh(y_true, y_pred, head_size, refp=0.5):\n",
    "    '''\n",
    "    Compute the PCKh measure (using refp of the head size) on predicted samples\n",
    "    \n",
    "    y_true: [batch_size, nb_joints, 2]\n",
    "    y_pred: [batch_size, nb_joints, 2]\n",
    "    head_size: [batch_size, 1]\n",
    "    '''\n",
    "\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    assert len(y_true) == len(head_size)\n",
    "    num_samples = len(y_true)\n",
    "\n",
    "    # Ignore the joints 6 and 7 (pelvis and thorax respectively), according to the file 'annolist2matrix.m' WHY\n",
    "    used_joints = [2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 8, 9]\n",
    "    y_true = y_true[:, used_joints, :]\n",
    "    y_pred = y_pred[:, used_joints, :]\n",
    "    dist = np.zeros((num_samples, len(used_joints)))\n",
    "    valid = np.zeros((num_samples, len(used_joints)))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        valid[i,:] = _valid_joints(y_true[i])\n",
    "        \n",
    "        norm = _norm(y_true[i] - y_pred[i], axis=1)\n",
    "        dist[i,:] = _norm(y_true[i] - y_pred[i], axis=1) / head_size[i]\n",
    "        print(\"distance norm between true %s and pred %s : %s (head size %s)\" % (str(y_true[i]), str(y_pred[i]), norm, head_size[i]))\n",
    "    match = (dist <= refp) * valid\n",
    "\n",
    "    return match.sum() / valid.sum()\n",
    "\n",
    "\n",
    "def pckh_per_joint(y_true, y_pred, head_size, pose_layout, refp=0.5, verbose=1):\n",
    "    '''\n",
    "    Compute the PCKh measure (using refp of the head size) on predicted\n",
    "    samples per joint and output the results.\n",
    "\n",
    "    y_true: [num_samples, nb_joints, 2]\n",
    "    y_pred: [num_samples, nb_joints, 2]\n",
    "    head_size: [num_samples, 1]\n",
    "    pose_layout: from deephar.utils.pose\n",
    "    '''\n",
    "\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    assert len(y_true) == len(head_size)\n",
    "\n",
    "    num_samples = len(y_true)\n",
    "    num_joints = pose_layout.num_joints\n",
    "    dist = np.zeros((num_samples, num_joints))\n",
    "    valid = np.zeros((num_samples, num_joints))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        valid[i,:] = _valid_joints(y_true[i])\n",
    "        dist[i,:] = _norm(y_true[i] - y_pred[i], axis=1) / head_size[i]\n",
    "\n",
    "    for j in range(num_joints):\n",
    "        jname = pose_layout.joint_names[j]\n",
    "        space = 7*' '\n",
    "        ss = len(space) - len(jname)\n",
    "        if verbose:\n",
    "            printc(HEADER, jname + space[0:ss] + '| ')\n",
    "    if verbose:\n",
    "        print ('')\n",
    "\n",
    "    match = (dist <= refp) * valid\n",
    "    for j in range(num_joints):\n",
    "        pck = match[:, j].sum() / valid[:, j].sum()\n",
    "        if verbose:\n",
    "            printc(OKBLUE, ' %.2f | ' % (100 * pck))\n",
    "    if verbose:\n",
    "        print ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "HEADER = '\\033[95m'\n",
    "OKBLUE = '\\033[94m'\n",
    "OKGREEN = '\\033[92m'\n",
    "WARNING = '\\033[93m'\n",
    "FAIL = '\\033[91m'\n",
    "ENDC = '\\033[0m'\n",
    "\n",
    "def printc(color, vmsg):\n",
    "    print (color + vmsg + ENDC, end='')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "def printcn(color, vmsg):\n",
    "    print (color + vmsg + ENDC)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "def _valid_joints(y, min_valid=-1e6):\n",
    "    def and_all(x):\n",
    "        if x.all():\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    return np.apply_along_axis(and_all, axis=1, arr=(y > min_valid))\n",
    "\n",
    "\n",
    "def _norm(x, axis=None):\n",
    "    return np.sqrt(np.sum(np.power(x, 2), axis=axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x_val], [y_val, pose_val, afmat_val, head_val] = data_val_mpii[0]\n",
    "eval_mpii_pckh(eval_model, x_val, pose_val, head_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_val_mpii.get_data(1, VALID_MODE)\n",
    "print(data['frame'].shape)\n",
    "pred = eval_model.predict(data['frame'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '/home/caleml/pe_experiments/exp_baseline_1b_bs32_h36m_201903221052/weights_032.h5'\n",
    "eval_model = MultiBranchModel(dim=3, n_joints=17, nb_pose_blocks=1)\n",
    "eval_model.load_weights(weights_path, pose_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_human36m_sc_error(\n",
    "    model, \n",
    "    x, \n",
    "    pose_w, \n",
    "    afmat, \n",
    "    rootz, \n",
    "    scam, \n",
    "    resol_z=2000., \n",
    "    batch_size=8, \n",
    "    map_to_pa17j=None, \n",
    "    logdir=None,\n",
    "    verbose=True):\n",
    "\n",
    "    assert len(x) == len(pose_w) == len(afmat) == len(scam)\n",
    "\n",
    "    input_shape = model.input_shape\n",
    "    num_blocks = len(model.outputs)\n",
    "\n",
    "    y_true_w = pose_w.copy()\n",
    "    if map_to_pa17j is not None:\n",
    "        y_true_w = y_true_w[:, map_to_pa17j, :]\n",
    "    y_pred_w = np.zeros((num_blocks,) + y_true_w.shape)\n",
    "    if rootz.ndim == 1:\n",
    "        rootz = np.expand_dims(rootz, axis=-1)\n",
    "\n",
    "    pred = model.predict(x, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Move the root joints from GT poses to origin\n",
    "    y_true_w -= y_true_w[:,0:1,:]\n",
    "\n",
    "    if verbose:\n",
    "        printc(WARNING, 'Avg. mm. error:')\n",
    "\n",
    "    lower_err = np.inf\n",
    "    lower_i = -1\n",
    "    scores = []\n",
    "\n",
    "    for b in range(num_blocks):\n",
    "\n",
    "        if num_blocks > 1:\n",
    "            y_pred = pred[b]\n",
    "        else:\n",
    "            y_pred = pred\n",
    "\n",
    "        # ??\n",
    "        y_pred = y_pred[:, :, 0:3]\n",
    "\n",
    "        # Project normalized coordiates to the image plane\n",
    "        y_pred[:, :, 0:2] = transform_pose_sequence(afmat.copy(), y_pred[:, :, 0:2], inverse=True)\n",
    "\n",
    "        \"\"\"Recover the absolute Z.\"\"\"\n",
    "        y_pred[:, :, 2] = (resol_z * (y_pred[:, :, 2] - 0.5)) + rootz\n",
    "        if map_to_pa17j is not None:\n",
    "            y_pred_uvd = y_pred[:, map_to_pa17j, 0:3]\n",
    "        else:\n",
    "            y_pred_uvd = y_pred[:, :, 0:3]\n",
    "\n",
    "        \"\"\"Do the camera inverse projection.\"\"\"\n",
    "        for j in range(len(y_pred_uvd)):\n",
    "            cam = camera_deserialize(scam[j])\n",
    "            y_pred_w[b, j, :, :] = cam.inverse_project(y_pred_uvd[j])\n",
    "\n",
    "        \"\"\"Move the root joint from predicted poses to the origin.\"\"\"\n",
    "        y_pred_w[b, :, :, :] -= y_pred_w[b, :, 0:1, :]\n",
    "\n",
    "        err_w = mean_distance_error(y_true_w[:, 0:, :], y_pred_w[b, :, 0:, :])\n",
    "        scores.append(err_w)\n",
    "        if verbose:\n",
    "            printc(WARNING, ' %.1f' % err_w)\n",
    "\n",
    "        \"\"\"Keep the best prediction and its index.\"\"\"\n",
    "        if err_w < lower_err:\n",
    "            lower_err = err_w\n",
    "            lower_i = b\n",
    "\n",
    "    if verbose:\n",
    "        printcn('', '')\n",
    "\n",
    "    if logdir is not None:\n",
    "        np.save('%s/y_pred_w.npy' % logdir, y_pred_w)\n",
    "        np.save('%s/y_true_w.npy' % logdir, y_true_w)\n",
    "\n",
    "    printcn(WARNING, 'Final averaged error (mm): %.3f' % lower_err)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h36m_val = BatchLoader(local_h36m, \n",
    "                       ['frame'],\n",
    "                       ['pose_w', 'pose_uvd', 'afmat', 'camera'], \n",
    "                       VALID_MODE,\n",
    "                       batch_size=local_h36m.get_length(VALID_MODE), \n",
    "                       shuffle=True)\n",
    "\n",
    "printcn(OKBLUE, 'Preloading Human3.6M validation samples...')\n",
    "\n",
    "[x_val], [pw_val, puvd_val, afmat_val, scam_val] = h36m_val[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = eval_human36m_sc_error(eval_model.model, \n",
    "                                x_val, \n",
    "                                pw_val, \n",
    "                                afmat_val,\n",
    "                                puvd_val[:,0,2], \n",
    "                                scam_val,  \n",
    "                                batch_size=24)\n",
    "\n",
    "pprint(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_cols = 2\n",
    "n_rows = len(data['frame'])\n",
    "fig = plt.figure(figsize=(8, 75))\n",
    "\n",
    "print(len(data['frame']))\n",
    "print(len(pred[0]))\n",
    "\n",
    "i_img = 1\n",
    "for i, data_img in enumerate(data['frame']):\n",
    "    fig.add_subplot(n_rows, n_cols, i_img)\n",
    "    plt.imshow(data_img)\n",
    "    \n",
    "    pred_img = pred[0][i]\n",
    "    fig.add_subplot(n_rows, n_cols, i_img + 1)\n",
    "    plt.imshow(pred_img)\n",
    "    \n",
    "    i_img += 2\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pred[0][0]\n",
    "print(img.shape)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "data_img = data['frame'][0]\n",
    "imgplot = plt.imshow(data_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pouet(definition):\n",
    "    \n",
    "    ret = list()\n",
    "    for elt in definition:\n",
    "        ret.append('truc')\n",
    "        \n",
    "    return tuple(ret)\n",
    "\n",
    "a = pouet('a')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(i):\n",
    "    def loss(a):\n",
    "        return a * i\n",
    "    return loss\n",
    "\n",
    "losses = list()\n",
    "for i in range(10):\n",
    "    losses.append(wrapper(i))\n",
    "    \n",
    "print(len(losses))\n",
    "for loss_fn in losses:\n",
    "    print(loss_fn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1]\n",
    "poses = [1, 2, 3, 4]\n",
    "\n",
    "outputs = a + poses + [5] + 6\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "a = 8\n",
    "indexes = list(range(a))\n",
    "random.shuffle(indexes)\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
