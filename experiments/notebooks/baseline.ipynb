{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/caleml/main-pe/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, Convolution2D, Activation, BatchNormalization, Reshape\n",
    "from tensorflow.keras.layers import Permute\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.datasets.mpii import MpiiSinglePerson\n",
    "from data.utils.data_utils import TEST_MODE, TRAIN_MODE, VALID_MODE\n",
    "from data.loader import BatchLoader\n",
    "\n",
    "from model import layers\n",
    "from model import losses\n",
    "from model import config\n",
    "from model import callbacks\n",
    "from model.utils import pose_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_shape = (256, 256, 3)\n",
    "        self.start_lr = 0.001\n",
    "        \n",
    "    def stem(self, inp):\n",
    "        '''\n",
    "        common first stem\n",
    "        '''\n",
    "        print(inp.shape)\n",
    "        stem_input = Input(shape=inp.shape[1:]) # 256 x 256 x 3\n",
    "\n",
    "        x = layers.conv_bn_act(stem_input, 32, (3, 3), strides=(2, 2))\n",
    "        x = layers.conv_bn_act(x, 32, (3, 3))\n",
    "        x = layers.conv_bn_act(x, 64, (3, 3))\n",
    "\n",
    "        a = layers.conv_bn_act(x, 96, (3, 3), strides=(2, 2))\n",
    "        b = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "        x = concatenate([a, b])\n",
    "\n",
    "        a = layers.conv_bn_act(x, 64, (1, 1))\n",
    "        a = layers.conv_bn(a, 96, (3, 3))\n",
    "        b = layers.conv_bn_act(x, 64, (1, 1))\n",
    "        b = layers.conv_bn_act(b, 64, (5, 1))\n",
    "        b = layers.conv_bn_act(b, 64, (1, 5))\n",
    "        b = layers.conv_bn(b, 96, (3, 3))\n",
    "        x = concatenate([a, b])\n",
    "\n",
    "        a = layers.act_conv_bn(x, 192, (3, 3), strides=(2, 2))\n",
    "        b = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "        x = concatenate([a, b])\n",
    "\n",
    "        x = layers.sepconv_residual(x, 3*192, name='sepconv1')\n",
    "\n",
    "        model = Model(stem_input, x, name='stem')\n",
    "        x = model(inp)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def pose_model(self, inp):\n",
    "        stem_out = self.stem(inp)\n",
    "        \n",
    "        out = stem_out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def appearance_model(self, inp):\n",
    "        out = ResNet50(inp)\n",
    "        return out\n",
    "    \n",
    "    def build(self):\n",
    "        '''\n",
    "        Input: 256 x 256 x 3 image\n",
    "        Outputs: \n",
    "            - pose tensor\n",
    "            - reconstructed image\n",
    "        \n",
    "        1. E_p is the encoder for the pose estimation\n",
    "        2. E_a is the encoder for the appearance\n",
    "        3. concat z_a and z_p to form the input of the decoder\n",
    "        4. decode into an image\n",
    "        '''\n",
    "        inp = Input(shape=self.input_shape)\n",
    "        \n",
    "        # 1. E_p\n",
    "        z_p, pred_pose = self.pose_model(inp)\n",
    "        \n",
    "        # 2. E_a\n",
    "        z_a = self.appearance_model(inp)\n",
    "        \n",
    "        # 3. reconstruction base\n",
    "        concat = self.prepare_concat(z_p, z_a)\n",
    "        \n",
    "        # 4. decoding\n",
    "        rec_img = self.decoder(concat)\n",
    "        \n",
    "        outputs = [pred_pose, rec_img]\n",
    "        self.model = Model(inputs=inp, outputs=outputs)\n",
    "        \n",
    "        # compile it\n",
    "        loss = losses.combined_loss()\n",
    "        self.model.compile(loss=loss, optimizer=RMSprop(lr=self.start_lr))\n",
    "        self.model.summary()\n",
    "        \n",
    "    def train(self, data_tr, steps_per_epoch):\n",
    "        callbacks = []\n",
    "        callbacks.append(SaveModel(weights_path))\n",
    "        callbacks.append(mpii_callback)\n",
    "        # callbacks.append(h36m_callback)\n",
    "\n",
    "        model.fit_generator(\n",
    "            data_tr,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=60,\n",
    "            callbacks=callbacks,\n",
    "            workers=8,\n",
    "            initial_epoch=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppearanceModel(object):\n",
    "    '''\n",
    "    Only autoencoding z_a for now\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_shape = (256, 256, 3)\n",
    "        self.start_lr = 0.001\n",
    "        \n",
    "    def decoder(self):\n",
    "        pass\n",
    "    \n",
    "    def build(self):\n",
    "        inp = Input(shape=self.input_shape)\n",
    "        \n",
    "        enc_model = ResNet50(include_top=False, weights='imagenet', input_tensor=inp)\n",
    "        \n",
    "        z_a = enc_model.output   # 8 x 8 x 2048\n",
    "        \n",
    "        # decoder part\n",
    "        up = layers.up(z_a)  # 16 x 16\n",
    "        up = layers.conv_bn_act(up, 512, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 512, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 512, (3, 3))\n",
    "        \n",
    "        up = layers.up(up)  # 32 x 32\n",
    "        up = layers.conv_bn_act(up, 512, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 512, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 256, (3, 3))\n",
    "        \n",
    "        up = layers.up(up)  # 64 x 64\n",
    "        up = layers.conv_bn_act(up, 256, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 256, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 128, (3, 3))\n",
    "        \n",
    "        up = layers.up(up)  # 128 x 128\n",
    "        up = layers.conv_bn_act(up, 128, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 64, (3, 3))\n",
    "        \n",
    "        up = layers.up(up)  # 256 x 256\n",
    "        up = layers.conv_bn_act(up, 3, (3, 3))\n",
    "        up = layers.conv_bn(up, 3, (1, 1))   # 3 channels, output shape of this should be (None, 3, 256, 256)\n",
    "            \n",
    "        # TODO: should we permute here or have the input formatted with channels first?\n",
    "        # perm = Permute((1, 2))(up)\n",
    "        # i_hat = Permute((2, 3))(perm)\n",
    "        i_hat = up\n",
    "        \n",
    "        self.model = Model(inputs=inp, outputs=i_hat)\n",
    "        \n",
    "        # loss = losses.combined_loss()\n",
    "        loss = mean_squared_error\n",
    "        \n",
    "        # run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "        # self.model.compile(loss=loss, optimizer=RMSprop(lr=self.start_lr), options=run_opts)\n",
    "        self.model.compile(loss=loss, optimizer=RMSprop(lr=self.start_lr))\n",
    "        self.model.summary()\n",
    "        \n",
    "    def train(self, data_tr, steps_per_epoch, model_folder):\n",
    "        weights_file = os.path.join(model_folder, 'weights_mpii_{epoch:03d}.h5')\n",
    "        \n",
    "        cb_list = []\n",
    "        cb_list.append(callbacks.SaveModel(weights_file))\n",
    "        # callbacks.append(LearningRateScheduler(lr_scheduler))\n",
    "        # callbacks.append(eval_callback)\n",
    "\n",
    "        self.model.fit_generator(data_tr,\n",
    "                                 steps_per_epoch=steps_per_epoch,\n",
    "                                 epochs=60,\n",
    "                                 callbacks=cb_list,\n",
    "                                 workers=4,\n",
    "                                 initial_epoch=0)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_shape = (256, 256, 3)\n",
    "        self.start_lr = 0.001\n",
    "        \n",
    "    def build(self):\n",
    "        img_w = 256\n",
    "        img_h = 256\n",
    "\n",
    "        kernel = 3\n",
    "\n",
    "        encoding_layers = [\n",
    "            Convolution2D(64, kernel, padding='same', input_shape=self.input_shape),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(64, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "\n",
    "            Convolution2D(128, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(128, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "\n",
    "            Convolution2D(256, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(256, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(256, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "\n",
    "            Convolution2D(512, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(512, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(512, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "\n",
    "            Convolution2D(512, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(512, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(512, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            MaxPooling2D(),\n",
    "        ]\n",
    "\n",
    "        autoencoder = Sequential()\n",
    "        autoencoder.encoding_layers = encoding_layers\n",
    "\n",
    "        for l in autoencoder.encoding_layers:\n",
    "            autoencoder.add(l)\n",
    "            # print(l.input_shape,l.output_shape,l)\n",
    "\n",
    "        decoding_layers = [\n",
    "            UpSampling2D(),\n",
    "            Convolution2D(512, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(512, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(512, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            UpSampling2D(),\n",
    "            Convolution2D(512, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(512, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(256, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            UpSampling2D(),\n",
    "            Convolution2D(256, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(256, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(128, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            UpSampling2D(),\n",
    "            Convolution2D(128, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(64, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "\n",
    "            UpSampling2D(),\n",
    "            Convolution2D(64, kernel, kernel, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu'),\n",
    "            Convolution2D(64, 1, 1, padding='same'),\n",
    "            BatchNormalization(),\n",
    "            Activation('relu')\n",
    "        ]\n",
    "        autoencoder.decoding_layers = decoding_layers\n",
    "        for l in autoencoder.decoding_layers:\n",
    "            autoencoder.add(l)\n",
    "\n",
    "        autoencoder.add(Reshape((3, img_h * img_w)))\n",
    "        self.model = autoencoder\n",
    "        \n",
    "        # loss = losses.elastic_loss()\n",
    "        run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "        self.model.compile(loss=mean_squared_error, optimizer=RMSprop(lr=self.start_lr), options=run_opts)\n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h36m_path = \"/share/DEEPLEARNING/datasets/human36m\"\n",
    "mpii_path = \"/share/DEEPLEARNING/datasets/mpii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h36m dataset loading\n",
    "h36m = Human36M(h36m_path, dataconf=config.human36m_dataconf, poselayout=pose_format.pa17j3d, topology='frames')\n",
    "\n",
    "data_tr = BatchLoader(\n",
    "    [h36m], \n",
    "    ['frame'], \n",
    "    ['pose'],\n",
    "    TRAIN_MODE, \n",
    "    batch_size=h36m.get_length(TRAIN_MODE),\n",
    "    num_predictions=num_predictions, \n",
    "    shuffle=True)\n",
    "\n",
    "# batch_size=[batch_size_mpii, batch_size_mpii, batch_size_ar, batch_size_ar], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "h36m_val = BatchLoader(\n",
    "    h36m, \n",
    "    ['frame'],\n",
    "    ['pose_w', 'pose_uvd', 'afmat', 'camera', 'action'], \n",
    "    VALID_MODE,\n",
    "    batch_size=h36m.get_length(VALID_MODE), \n",
    "    shuffle=True)\n",
    "\n",
    "[x_val], [pw_val, puvd_val, afmat_val, scam_val, action] = h36m_val[0]\n",
    "\n",
    "h36m_callback = H36MEvalCallback(x_val, pw_val, afmat_val, puvd_val[:,0,2], scam_val, action, logdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpii = MpiiSinglePerson(mpii_path, dataconf=config.mpii_dataconf, poselayout=pose_format.pa17j3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr_mpii = BatchLoader(\n",
    "    mpii, \n",
    "    ['frame'], \n",
    "    ['frame'], \n",
    "    TRAIN_MODE,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_tr_mpii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder()\n",
    "model.build()\n",
    "\n",
    "# steps_per_epoch = h36m.get_length(TRAIN_MODE) // batch_size_h36m\n",
    "steps_per_epoch = mpii.get_length(TRAIN_MODE) // batch_size_mpii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data_tr, steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AppearanceModel()\n",
    "model.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'appearance'\n",
    "dataset_name = 'mpii'\n",
    "model_folder = '/home/caleml/pe_experiments/exp_%s_%s_%s' % (model_name, dataset_name, datetime.datetime.now().strftime(\"%Y%m%d%H%M\")) \n",
    "os.makedirs(model_folder)\n",
    "model.train(data_tr_mpii, steps_per_epoch=len(data_tr_mpii), model_folder=model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
