{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/caleml/main-pe/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, UpSampling2D, Convolution2D, Activation, BatchNormalization, Reshape\n",
    "from tensorflow.keras.layers import Permute, add, concatenate\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.datasets.mpii import MpiiSinglePerson\n",
    "from data.utils.data_utils import TEST_MODE, TRAIN_MODE, VALID_MODE\n",
    "from data.loader import BatchLoader\n",
    "\n",
    "from model import blocks\n",
    "from model import layers\n",
    "from model import losses\n",
    "from model import config\n",
    "from model import callbacks\n",
    "from model.models import BaseModel, AppearanceModel\n",
    "from model.utils import pose_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_shape = (256, 256, 3)\n",
    "        self.start_lr = 0.001\n",
    "        \n",
    "    def stem(self, inp):\n",
    "        '''\n",
    "        common first stem\n",
    "        '''\n",
    "        print(inp.shape)\n",
    "        stem_input = Input(shape=inp.shape[1:]) # 256 x 256 x 3\n",
    "\n",
    "        x = layers.conv_bn_act(stem_input, 32, (3, 3), strides=(2, 2))\n",
    "        x = layers.conv_bn_act(x, 32, (3, 3))\n",
    "        x = layers.conv_bn_act(x, 64, (3, 3))\n",
    "\n",
    "        a = layers.conv_bn_act(x, 96, (3, 3), strides=(2, 2))\n",
    "        b = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "        x = concatenate([a, b])\n",
    "\n",
    "        a = layers.conv_bn_act(x, 64, (1, 1))\n",
    "        a = layers.conv_bn(a, 96, (3, 3))\n",
    "        b = layers.conv_bn_act(x, 64, (1, 1))\n",
    "        b = layers.conv_bn_act(b, 64, (5, 1))\n",
    "        b = layers.conv_bn_act(b, 64, (1, 5))\n",
    "        b = layers.conv_bn(b, 96, (3, 3))\n",
    "        x = concatenate([a, b])\n",
    "\n",
    "        a = layers.act_conv_bn(x, 192, (3, 3), strides=(2, 2))\n",
    "        b = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "        x = concatenate([a, b])\n",
    "\n",
    "        x = layers.sepconv_residual(x, 3*192, name='sepconv1')\n",
    "\n",
    "        model = Model(stem_input, x, name='stem')\n",
    "        x = model(inp)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def pose_model(self, inp):\n",
    "        stem_out = self.stem(inp)\n",
    "        \n",
    "        out = stem_out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def appearance_model(self, inp):\n",
    "        out = ResNet50(inp)\n",
    "        return out\n",
    "    \n",
    "    def build(self):\n",
    "        '''\n",
    "        Input: 256 x 256 x 3 image\n",
    "        Outputs: \n",
    "            - pose tensor\n",
    "            - reconstructed image\n",
    "        \n",
    "        1. E_p is the encoder for the pose estimation\n",
    "        2. E_a is the encoder for the appearance\n",
    "        3. concat z_a and z_p to form the input of the decoder\n",
    "        4. decode into an image\n",
    "        '''\n",
    "        inp = Input(shape=self.input_shape)\n",
    "        \n",
    "        # 1. E_p\n",
    "        z_p, pred_pose = self.pose_model(inp)\n",
    "        \n",
    "        # 2. E_a\n",
    "        z_a = self.appearance_model(inp)\n",
    "        \n",
    "        # 3. reconstruction base\n",
    "        concat = self.prepare_concat(z_p, z_a)\n",
    "        \n",
    "        # 4. decoding\n",
    "        rec_img = self.decoder(concat)\n",
    "        \n",
    "        outputs = [pred_pose, rec_img]\n",
    "        self.model = Model(inputs=inp, outputs=outputs)\n",
    "        \n",
    "        # compile it\n",
    "        loss = losses.combined_loss()\n",
    "        self.model.compile(loss=loss, optimizer=RMSprop(lr=self.start_lr))\n",
    "        self.model.summary()\n",
    "        \n",
    "    def train(self, data_tr, steps_per_epoch):\n",
    "        callbacks = []\n",
    "        callbacks.append(SaveModel(weights_path))\n",
    "        callbacks.append(mpii_callback)\n",
    "        # callbacks.append(h36m_callback)\n",
    "\n",
    "        model.fit_generator(\n",
    "            data_tr,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=60,\n",
    "            callbacks=callbacks,\n",
    "            workers=8,\n",
    "            initial_epoch=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OldAppearanceModel(object):\n",
    "    '''\n",
    "    Only autoencoding z_a for now\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_shape = (256, 256, 3)\n",
    "        self.start_lr = 0.001\n",
    "        \n",
    "    def decoder(self):\n",
    "        pass\n",
    "    \n",
    "    def build(self):\n",
    "        inp = Input(shape=self.input_shape)\n",
    "        \n",
    "        enc_model = ResNet50(include_top=False, weights='imagenet', input_tensor=inp)\n",
    "        \n",
    "        z_a = enc_model.output   # 8 x 8 x 2048\n",
    "        \n",
    "        # decoder part\n",
    "        up = layers.up(z_a)  # 16 x 16\n",
    "        up = layers.conv_bn_act(up, 512, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 512, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 512, (3, 3))\n",
    "        \n",
    "        up = layers.up(up)  # 32 x 32\n",
    "        up = layers.conv_bn_act(up, 512, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 512, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 256, (3, 3))\n",
    "        \n",
    "        up = layers.up(up)  # 64 x 64\n",
    "        up = layers.conv_bn_act(up, 256, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 256, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 128, (3, 3))\n",
    "        \n",
    "        up = layers.up(up)  # 128 x 128\n",
    "        up = layers.conv_bn_act(up, 128, (3, 3))\n",
    "        up = layers.conv_bn_act(up, 64, (3, 3))\n",
    "        \n",
    "        up = layers.up(up)  # 256 x 256\n",
    "        up = layers.conv_bn_act(up, 3, (3, 3))\n",
    "        up = layers.conv_bn(up, 3, (1, 1))   # 3 channels, output shape of this should be (None, 3, 256, 256)\n",
    "            \n",
    "        # TODO: should we permute here or have the input formatted with channels first?\n",
    "        # perm = Permute((1, 2))(up)\n",
    "        # i_hat = Permute((2, 3))(perm)\n",
    "        i_hat = up\n",
    "        \n",
    "        self.model = Model(inputs=inp, outputs=i_hat)\n",
    "        \n",
    "        # loss = losses.combined_loss()\n",
    "        loss = mean_squared_error\n",
    "        \n",
    "        # run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "        # self.model.compile(loss=loss, optimizer=RMSprop(lr=self.start_lr), options=run_opts)\n",
    "        self.model.compile(loss=loss, optimizer=RMSprop(lr=self.start_lr))\n",
    "        self.model.summary()\n",
    "        \n",
    "    def train(self, data_tr, steps_per_epoch, model_folder):\n",
    "        weights_file = os.path.join(model_folder, 'weights_mpii_{epoch:03d}.h5')\n",
    "        \n",
    "        cb_list = []\n",
    "        cb_list.append(callbacks.SaveModel(weights_file))\n",
    "        # callbacks.append(LearningRateScheduler(lr_scheduler))\n",
    "        # callbacks.append(eval_callback)\n",
    "\n",
    "        self.model.fit_generator(data_tr,\n",
    "                                 steps_per_epoch=steps_per_epoch,\n",
    "                                 epochs=60,\n",
    "                                 callbacks=cb_list,\n",
    "                                 workers=4,\n",
    "                                 initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseModel(object):\n",
    "    \n",
    "    def __init__(self, input_tensor, n_joints, n_blocks, kernel_size):\n",
    "        self.n_joints = n_joints\n",
    "        self.n_blocks = n_blocks\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.n_heatmaps = self.n_joints   # this seems silly but we will augment with context later\n",
    "        \n",
    "        self.build(input_tensor)\n",
    "        return self.model\n",
    "        \n",
    "    def build(self, inp):\n",
    "        '''\n",
    "        1. stem\n",
    "        2. stacking the blocks\n",
    "        '''\n",
    "        \n",
    "        outputs = list()\n",
    "        x = self.stem(inp)\n",
    "        \n",
    "        for i_block in range(self.n_blocks):\n",
    "            x = self.reception_block(x, name='rBlock%d' % (i_block + 1))\n",
    "            \n",
    "            x = self.sepconv_block(x, name='SepConv%d' % (i_block + 1))\n",
    "            h = self.pose_block(x, name='RegMap%d' % (i_block + 1))\n",
    "            \n",
    "            pose = self.pose_regression_2d(h)\n",
    "            \n",
    "            outputs.append(pose)\n",
    "            # outputs.append(visible)\n",
    "            outputs.append(h)\n",
    "\n",
    "            if bidx < num_blocks - 1:\n",
    "                h = build_fremap_block(h, block_shape[-1], name='fReMap%d' % (bidx + 1))\n",
    "                x = add([ident_map, x, h])\n",
    "            \n",
    "        self.model = Model(inputs=inp, outputs=outputs)\n",
    "        \n",
    "    def stem(self, inp):\n",
    "        '''\n",
    "        inception v4 stem\n",
    "        \n",
    "        input: 256 x 256 x 3\n",
    "        output: 32 x 32 x 576\n",
    "        '''\n",
    "        xi = Input(shape=inp.get_shape().as_list()[1:]) # 256 x 256 x 3\n",
    "\n",
    "        x = layers.conv_bn_act(xi, 32, (3, 3), strides=(2, 2))\n",
    "        x = layers.conv_bn_act(x, 32, (3, 3))\n",
    "        x = layers.conv_bn_act(x, 64, (3, 3))\n",
    "\n",
    "        a = layers.conv_bn_act(x, 96, (3, 3), strides=(2, 2))\n",
    "        b = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "        x = concatenate([a, b])\n",
    "\n",
    "        a = layers.conv_bn_act(x, 64, (1, 1))\n",
    "        a = layers.conv_bn(a, 96, (3, 3))\n",
    "        b = layers.conv_bn_act(x, 64, (1, 1))\n",
    "        b = layers.conv_bn_act(b, 64, (5, 1))\n",
    "        b = layers.conv_bn_act(b, 64, (1, 5))\n",
    "        b = layers.conv_bn(b, 96, (3, 3))\n",
    "        x = concatenate([a, b])\n",
    "\n",
    "        a = layers.act_conv_bn(x, 192, (3, 3), strides=(2, 2))\n",
    "        b = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "        x = concatenate([a, b])\n",
    "\n",
    "        x = blocks.sepconv_residual(x, 3*192, name='sepconv1')\n",
    "\n",
    "        model = Model(xi, x, name='Stem')\n",
    "        x = model(inp)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def reception_block(self, inp, name):\n",
    "        '''\n",
    "        each pose block starts with a reception block\n",
    "        it is u-shaped and relies on separable convolutions\n",
    "        \n",
    "        inp ------------------------- a (SR 576) -------------------- + -- out\n",
    "          |                                                           |\n",
    "          |                                                           |\n",
    "          MP --- C 288 -- SR 288 ---- b (SR 288) ---- + -- SR 576 -- US\n",
    "                            |                         |\n",
    "                            |                         |\n",
    "                            MP --- SR -- SR -- SR --- US     <- all 288 channels\n",
    "                            \n",
    "          \n",
    "        SR: Sepconv Residual (all 5x5)\n",
    "        C: Conv (1x1)\n",
    "        MP: Max Pooling (2x2 with stride 2x2)\n",
    "        US: UpSampling (2x2)\n",
    "        \n",
    "        input: 32 x 32 x 576\n",
    "        output: 32 x 32 x 576\n",
    "        '''\n",
    "        ksize = self.kernel_size\n",
    "        \n",
    "        input_shape = inp.get_shape().as_list()[1:]\n",
    "        print(\"INPUT SHAPE %s %s\" % (type(input_shape), str(input_shape)))\n",
    "        size = int(input_shape[-1])\n",
    "\n",
    "        # first branch\n",
    "        xi = Input(shape=input_shape)\n",
    "        a = blocks.sepconv_residual(xi, size, name='sepconv_l1', kernel_size=ksize)\n",
    "\n",
    "        # second branch\n",
    "        low1 = MaxPooling2D((2, 2))(xi)\n",
    "        low1 = layers.act_conv_bn(low1, int(size/2), (1, 1))\n",
    "        low1 = blocks.sepconv_residual(low1, int(size/2), name='sepconv_l2_1', kernel_size=ksize)\n",
    "        b = blocks.sepconv_residual(low1, int(size/2), name='sepconv_l2_2', kernel_size=ksize)\n",
    "\n",
    "        # third branch\n",
    "        c = MaxPooling2D((2, 2))(low1)\n",
    "        c = blocks.sepconv_residual(c, int(size/2), name='sepconv_l3_1', kernel_size=ksize)\n",
    "        c = blocks.sepconv_residual(c, int(size/2), name='sepconv_l3_2', kernel_size=ksize)\n",
    "        c = blocks.sepconv_residual(c, int(size/2), name='sepconv_l3_3', kernel_size=ksize)\n",
    "        c = UpSampling2D((2, 2))(c)\n",
    "\n",
    "        # merge second and third branches\n",
    "        b = add([b, c])\n",
    "        b = blocks.sepconv_residual(b, size, name='sepconv_l2_3', kernel_size=ksize)\n",
    "        b = UpSampling2D((2, 2))(b)\n",
    "        \n",
    "        # merge first and second branches\n",
    "        x = add([a, b])\n",
    "        model = Model(inputs=xi, outputs=x, name=name)\n",
    "\n",
    "        return model(inp)\n",
    "    \n",
    "    def sepconv_block(self, inp, name):\n",
    "        '''\n",
    "        Separable convolution\n",
    "        '''\n",
    "        input_shape = inp.get_shape().as_list()[1:]\n",
    "\n",
    "        xi = Input(shape=input_shape)\n",
    "        x = layers.separable_act_conv_bn(xi, input_shape[-1], self.kernel_size)\n",
    "\n",
    "        model = Model(inputs=xi, outputs=x, name=name)\n",
    "\n",
    "        return model(inp)\n",
    "        \n",
    "    def pose_block(self, inp, name):\n",
    "        '''\n",
    "        input: 32 x 32 x 576\n",
    "        output: 32 x 32 x 16 (number of heatmaps)\n",
    "        '''\n",
    "        input_shape = inp.get_shape().as_list()[1:]\n",
    "\n",
    "        xi = Input(shape=input_shape)\n",
    "        x = layers.act_conv(xi, self.n_heatmaps, (1, 1))\n",
    "\n",
    "        model = Model(inputs=xi, outputs=x, name=name)\n",
    "\n",
    "        return model(inp)\n",
    "    \n",
    "    def pose_regression_2d(heatmaps):\n",
    "        '''\n",
    "        soft argmax to get the pose from the heatmaps\n",
    "        \n",
    "        input: 32 x 32 x 16 (number of joints)\n",
    "        output: \n",
    "        '''\n",
    "        input_shape = inp.get_shape().as_list()[1:]\n",
    "        \n",
    "        pose = self.soft_argmax(heatmaps)\n",
    "        # visible = jprob_s_model(h)\n",
    "\n",
    "        return pose\n",
    "    \n",
    "    def soft_argmax(sams_input_shape, rho=0, name='sSAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBranchModel(BaseModel):\n",
    "    '''\n",
    "    2 branch model :\n",
    "    - appearance (z_a)\n",
    "    - pose (z_p)\n",
    "    One common decoder to recreate the image\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_joints=16, nb_pose_blocks=8, reception_kernel_size=(5,5)):\n",
    "        self.n_joints = n_joints\n",
    "        self.n_blocks = nb_pose_blocks\n",
    "        self.reception_kernel_size = reception_kernel_size\n",
    "        \n",
    "        BaseModel.__init__(self)\n",
    "        \n",
    "    def build(self):\n",
    "        inp = Input(shape=self.input_shape)\n",
    "        \n",
    "        z_a = self.appearance_encoder(inp)\n",
    "        z_p = self.pose_encoder(inp)\n",
    "        \n",
    "        # concat = self.concat(z_a, z_p)\n",
    "        \n",
    "        # i_hat = self.decoder(concat)\n",
    "        \n",
    "        # self.model = Model(inputs=inp, outputs=[z_p, i_hat])\n",
    "        self.model = Model(inputs=inp, outputs=[z_p, z_a])\n",
    "       \n",
    "        # loss = multi_loss\n",
    "        loss = mean_squared_error\n",
    "        self.model.compile(loss=loss, optimizer=RMSProp(lr=self.start_lr))\n",
    "        self.model.summary()\n",
    "        \n",
    "    def appearance_encoder(self, inp):\n",
    "        '''\n",
    "        resnet50 for now\n",
    "        input: 256 x 256 x 3\n",
    "        output: 8 x 8 x 2048\n",
    "        '''\n",
    "        enc_model = ResNet50(include_top=False, weights='imagenet', input_tensor=inp)\n",
    "        \n",
    "        z_a = enc_model.output   # 8 x 8 x 2048\n",
    "        return z_a\n",
    "    \n",
    "    def pose_encoder(self, inp):\n",
    "        '''\n",
    "        reception / stacked hourglass\n",
    "        input: 256 x 256 x 3\n",
    "        output: \n",
    "        '''\n",
    "        pose_model = PoseModel(inp, self.n_joints, self.n_blocks, self.reception_kernel_size)\n",
    "        out = pose_model.output\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def concat(self, z_a, z_p):\n",
    "        '''\n",
    "        concat pose and appearance representations before decoding\n",
    "        input:\n",
    "            - z_p: \n",
    "            - z_a: 8 x 8 x 2048\n",
    "        output:\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def decoder(self, concat):\n",
    "        '''\n",
    "        from concatenated representations to image reconstruction\n",
    "        input:\n",
    "        output: 256 x 256 x 3\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h36m_path = \"/share/DEEPLEARNING/datasets/human36m\"\n",
    "mpii_path = \"/share/DEEPLEARNING/datasets/mpii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h36m dataset loading\n",
    "h36m = Human36M(h36m_path, dataconf=config.human36m_dataconf, poselayout=pose_format.pa17j3d, topology='frames')\n",
    "\n",
    "data_tr = BatchLoader(\n",
    "    [h36m], \n",
    "    ['frame'], \n",
    "    ['pose'],\n",
    "    TRAIN_MODE, \n",
    "    batch_size=h36m.get_length(TRAIN_MODE),\n",
    "    num_predictions=num_predictions, \n",
    "    shuffle=True)\n",
    "\n",
    "# batch_size=[batch_size_mpii, batch_size_mpii, batch_size_ar, batch_size_ar], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "h36m_val = BatchLoader(\n",
    "    h36m, \n",
    "    ['frame'],\n",
    "    ['pose_w', 'pose_uvd', 'afmat', 'camera', 'action'], \n",
    "    VALID_MODE,\n",
    "    batch_size=h36m.get_length(VALID_MODE), \n",
    "    shuffle=True)\n",
    "\n",
    "[x_val], [pw_val, puvd_val, afmat_val, scam_val, action] = h36m_val[0]\n",
    "\n",
    "h36m_callback = H36MEvalCallback(x_val, pw_val, afmat_val, puvd_val[:,0,2], scam_val, action, logdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpii = MpiiSinglePerson(mpii_path, dataconf=config.mpii_dataconf, poselayout=pose_format.pa17j3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr_mpii = BatchLoader(\n",
    "    mpii, \n",
    "    ['frame'], \n",
    "    ['frame'], \n",
    "    TRAIN_MODE,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_tr_mpii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder()\n",
    "model.build()\n",
    "\n",
    "# steps_per_epoch = h36m.get_length(TRAIN_MODE) // batch_size_h36m\n",
    "steps_per_epoch = mpii.get_length(TRAIN_MODE) // batch_size_mpii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(data_tr, steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AppearanceModel()\n",
    "model.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'appearance'\n",
    "dataset_name = 'mpii'\n",
    "model_folder = '/home/caleml/pe_experiments/exp_%s_%s_%s' % (model_name, dataset_name, datetime.datetime.now().strftime(\"%Y%m%d%H%M\")) \n",
    "os.makedirs(model_folder)\n",
    "model.train(data_tr_mpii, steps_per_epoch=len(data_tr_mpii), model_folder=model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiBranchModel()\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multib'\n",
    "dataset_name = 'mpii'\n",
    "model_folder = '/home/caleml/pe_experiments/exp_%s_%s_%s' % (model_name, dataset_name, datetime.datetime.now().strftime(\"%Y%m%d%H%M\")) \n",
    "os.makedirs(model_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.models import AppearanceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = '/home/caleml/pe_experiments/exp_appearance_mpii_201902051901'\n",
    "model_checkpoint = '/home/caleml/pe_experiments/exp_appearance_mpii_201902051901/weights_mpii_058.h5'  # weights\n",
    "checkpoint_2 = '/home/caleml/pe_experiments/exp_appearance_mpii_201902061614/weights_mpii_013.h5'  # made with save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AppearanceModel()\n",
    "model.load(checkpoint_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval data\n",
    "mpii = MpiiSinglePerson(mpii_path, dataconf=config.mpii_dataconf, poselayout=pose_format.pa17j3d)\n",
    "data_val_mpii = BatchLoader(\n",
    "    mpii, \n",
    "    ['frame'], \n",
    "    ['frame'], \n",
    "    VALID_MODE,\n",
    "    shuffle=False)\n",
    "\n",
    "len(data_val_mpii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pouet(definition):\n",
    "    \n",
    "    ret = list()\n",
    "    for elt in definition:\n",
    "        ret.append('truc')\n",
    "        \n",
    "    return tuple(ret)\n",
    "\n",
    "a = pouet('a')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
